\section*{Statistical validation of ML models}
Expected Risk: $R(f) = \mathbb{E}[R(f, X)] =\int_\mathcal{X} \int_\mathcal{Y}\mathcal{L}(Y, f(X))P(Y|X)P(X)dydx $
Empirical Risk Minimizer (ERM) $\hat{f}$:\\
$\hat{f} \in \argmin_{f \in \mathcal{C}} \hat{R}(\hat{f}, Z^{train})$ (train risk)\\
$\hat{R}(\hat{f}, Z^{train}) = \frac{1}{n} \sum_{i=1}^n Q(Y_i, \hat{f}(X_i))$\\

\subsection*{K-Fold Cross Validation}
We train $\hat{f}^{-k(i)}$ on $\mathcal{Z}\setminus\mathcal{Z}_i$, then avg loss
$R(\mathcal{A})=\frac1n \sum_i \mathcal{L}(y_i, \hat{f}^{-k(i)}(x_i))$
\subsection*{Bootstrapping}
Create $\mathcal{Z}^{*b}$ by sampling with rep. da $\mathcal{Z}$\\
$\bar{S}\mathrm{=}\frac1B\sum_bS(\mathcal{Z}^{*b})$ ;
$\bar{\sigma}^2\mathrm{=}\frac1{B-1}\sum_b(S(\mathcal{Z}^{*b})\mathrm{-}\bar{S})$

\subsection*{Statistical validation}
Null hyp. $\mathcal{H}_0$ we want reject. Statistic $T$ \\
\textbf{p-value} $= P(T\geq t | \mathcal{H}_0)$ prob. of having something as extreme as $t$ if $\mathcal{H}_0$ was true
\textbf{Wald t.} $= \frac{\hat{\theta}-\theta_0}{\widehat{se}}$, with $\mathcal{H}_0:\theta=\theta_0$